{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1101_BAGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNqqwspcMU0P2UE8bfijYBJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HyelinNAM/2019SWTECHFAIR/blob/master/1101_BAGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEDJkBC_95GI"
      },
      "source": [
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7gSGwwTb_GZ",
        "outputId": "ba562ba5-b852-49e4-8df3-ebcbc3488f04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "manualSeed = 999\n",
        "print(\"Random seed:\",manualSeed)\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random seed: 999\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f8ac2de0588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpXFDexOORLm"
      },
      "source": [
        "latent_size = \n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G28QJfR7TLeX"
      },
      "source": [
        "# optimizer > Adam (lr, beta_1)\n",
        "# loss > sparse categorical crossentropy\n",
        "\n",
        "class Generator(nn.Module):\n",
        "\n",
        "    def __init__(self,latent_size,resolution, channels, init_resolution=8):\n",
        "        # latent_size > 인풋 z 벡터 사이즈, resolution > 목표하는 resolution, channels > 목표하는 channel 수,init_resolution > upsampling 전 목표 resolution\n",
        "        super(Generator,self).__init__()\n",
        "\n",
        "        self.layer1 = torch.nn.Sequential(\n",
        "            nn.Linear(latent_size,1024, bias=False),\n",
        "            F.relu()\n",
        "        )\n",
        "        \n",
        "        self.layer2 = torch.nn.Sequential(\n",
        "            nn.Linear(1024,128*init_resolution*init_resolution, bias=False)\n",
        "            F.relu()\n",
        "        )\n",
        "\n",
        "        crt_res = init_resolution # = min_latent_res (여기선 8)\n",
        "\n",
        "        while crt_res != resolution:\n",
        "\n",
        "            layer3 = [nn.Upsample(scale_factor=2,mode='nearest')]\n",
        "\n",
        "            in_features = 128\n",
        "            out_features = 256\n",
        "\n",
        "            if crt_res < resolution / 2:\n",
        "                \n",
        "                layer3 += [nn.Conv2d(in_features, out_features, 5, padding=2, bias=False),\n",
        "                           F.relu()]\n",
        "\n",
        "                in_features = out_features\n",
        "\n",
        "            else:\n",
        "                layer3 += [nn.Conv2d(in_features, 128, 5, padding=2, bias=False),\n",
        "                           F.relu()]\n",
        "\n",
        "            crt_res = crt_res * 2\n",
        "\n",
        "            assert crt_res <= resolution,\\\n",
        "                f'Error: Final resolution {resolution} must equal i * 2^n. Initial resolution i is {init_resolution}. n must be a natural number.'\n",
        "            \n",
        "    \n",
        "        self.layer3 = nn.Sequential(*layer3)\n",
        "\n",
        "        self.layer4 =  torch.nn.Sequential(\n",
        "            nn.Conv2d(128, channels, 3, padding=1, bias=False),\n",
        "            F.tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self,input):\n",
        "        x = self.layer1(input)\n",
        "        x = self.layer2(x)\n",
        "        x = torch.reshape(x, (128,init_resolution,init_resolution))\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwY0cohDmU9N"
      },
      "source": [
        "class Encoder(nn.Module): # 이미지 > latent vector\n",
        "    def __init__(self, \n",
        "                 \n",
        "                 latent_size,resolution, channels, init_resolution=8):\n",
        "        # latent_size > 인풋 z 벡터 사이즈, resolution > 목표하는 resolution, channels > 목표하는 channel 수,init_resolution > upsampling 전 목표 resolution\n",
        "        super(Encoder,self).__init__()\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fz666bP13KMl"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wC1UiWyd4J2T"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self,)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xb_BnixvlhkW"
      },
      "source": [
        "def weight_init(m):\n",
        "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "        nn.init.xavier_uniform_(m.weight, gain=nn.init.calculate_gain('relu')) # glorot_uniform\n",
        "        nn.init.zeros_(m.bias)\n",
        "\n",
        "model.apply(weight_init)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFhZF_IpNEk_"
      },
      "source": [
        "# 데이터 불러오기\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(64),\n",
        "    transforms.ToTensor(), \n",
        "    transforms.Normalize((0.5,),(0.5,)),\n",
        "])\n",
        "\n",
        "data = datasets.MNIST(root='data',download=True,train=True,transform=transform)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}